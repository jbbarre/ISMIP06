{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "#decoding time units and variable values in a netCDF file conforming to the Climate and Forecasting (CF) netCDF conventions.\n",
    "import cftime\n",
    "# progress bar\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ISMIP Variables\n",
    "\n",
    "try:\n",
    "    # load csv :\n",
    "    ismip  = pd.read_csv('/mnt/d/1_protect/0_sanity_check/ISMIP6/ismip6_criteria_v0.csv',delimiter=';',decimal=\",\")\n",
    "except IOError:\n",
    "    print('ERROR: Cannot open compliance criteria file (.csv required with ; as delimiter and , for decimal.)')\n",
    "else:\n",
    "    ismip_meta = ismip.to_dict('records')\n",
    "    # get the list of variables\n",
    "    ismip_var = [dic['variable'] for dic in ismip_meta]\n",
    "    # get the mandatory variables\n",
    "    ismip_mandatory_var = ismip['variable'][ismip.mandatory==1].tolist()\n",
    "\n",
    "    variables = ismip_var\n",
    "    mandatory_variables = ismip_mandatory_var\n",
    "\n",
    "#ismip.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments_ismip6 =[{'experiment':'hist', 'startinf':datetime.datetime(1979, 6, 30),'startsup':datetime.datetime(1980, 1, 1),'endinf':datetime.datetime(2014, 6, 30),'endsup':datetime.datetime(2015, 1, 1),'duration':35},\n",
    "                  {'experiment':'ctrl', 'startinf':datetime.datetime(1979, 6, 30),'startsup':datetime.datetime(1980, 1, 1),'endinf':datetime.datetime(2100,6,30),'endsup':datetime.datetime(2101, 1, 1),'duration':120},\n",
    "                  {'experiment':'ctrl_proj', 'startinf':datetime.datetime(2015, 1, 1),'startsup':datetime.datetime(2016, 1, 2),'endinf':datetime.datetime(2100,7,1),'endsup':datetime.datetime(2101, 1, 1),'duration':86},\n",
    "                  {'experiment':'exp01', 'startinf':datetime.datetime(2015, 1, 1),'startsup':datetime.datetime(2016, 1, 2),'endinf':datetime.datetime(2100,6,30),'endsup':datetime.datetime(2101, 1, 1),'duration':86},\n",
    "                  {'experiment':'exp02', 'startinf':datetime.datetime(2015, 1, 1),'startsup':datetime.datetime(2016, 1, 2),'endinf':datetime.datetime(2100,6,30),'endsup':datetime.datetime(2101, 1, 1),'duration':86},\n",
    "                  {'experiment':'exp03', 'startinf':datetime.datetime(2015, 1, 1),'startsup':datetime.datetime(2016, 1, 2),'endinf':datetime.datetime(2100,6,30),'endsup':datetime.datetime(2101, 1, 1),'duration':86},\n",
    "                  {'experiment':'exp04', 'startinf':datetime.datetime(2015, 1, 1),'startsup':datetime.datetime(2016, 1, 2),'endinf':datetime.datetime(2100,6,30),'endsup':datetime.datetime(2101, 1, 1),'duration':86},\n",
    "                  {'experiment':'exp05', 'startinf':datetime.datetime(2015, 1, 1),'startsup':datetime.datetime(2016, 1, 2),'endinf':datetime.datetime(2100,6,30),'endsup':datetime.datetime(2101, 1, 1),'duration':86},\n",
    "                  {'experiment':'exp06', 'startinf':datetime.datetime(2015, 1, 1),'startsup':datetime.datetime(2016, 1, 2),'endinf':datetime.datetime(2100,6,30),'endsup':datetime.datetime(2101, 1, 1),'duration':86},\n",
    "                  {'experiment':'exp07', 'startinf':datetime.datetime(2015, 1, 1),'startsup':datetime.datetime(2016, 1, 2),'endinf':datetime.datetime(2100,6,30),'endsup':datetime.datetime(2101, 1, 1),'duration':86},\n",
    "                  {'experiment':'exp08', 'startinf':datetime.datetime(2015, 1, 1),'startsup':datetime.datetime(2016, 1, 2),'endinf':datetime.datetime(2100,6,30),'endsup':datetime.datetime(2101, 1, 1),'duration':86},\n",
    "                  {'experiment':'exp09', 'startinf':datetime.datetime(2015, 1, 1),'startsup':datetime.datetime(2016, 1, 2),'endinf':datetime.datetime(2100,6,30),'endsup':datetime.datetime(2101, 1, 1),'duration':86},\n",
    "                  {'experiment':'exp10', 'startinf':datetime.datetime(2015, 1, 1),'startsup':datetime.datetime(2016, 1, 2),'endinf':datetime.datetime(2100,6,30),'endsup':datetime.datetime(2101, 1, 1),'duration':86},\n",
    "                  {'experiment':'exp11', 'startinf':datetime.datetime(2015, 1, 1),'startsup':datetime.datetime(2016, 1, 2),'endinf':datetime.datetime(2100,6,30),'endsup':datetime.datetime(2101, 1, 1),'duration':86},\n",
    "                  {'experiment':'exp12', 'startinf':datetime.datetime(2015, 1, 1),'startsup':datetime.datetime(2016, 1, 2),'endinf':datetime.datetime(2100,6,30),'endsup':datetime.datetime(2101, 1, 1),'duration':86},\n",
    "                  {'experiment':'exp13', 'startinf':datetime.datetime(2015, 1, 1),'startsup':datetime.datetime(2016, 1, 2),'endinf':datetime.datetime(2100,6,30),'endsup':datetime.datetime(2101, 1, 1),'duration':86}\n",
    "]\n",
    "\n",
    "scalar_variables_ismip6 = ['lim','limnsw','iareagr','iareafl','tendacabf','tendlibmassbf','tendlibmassbffl','tendlicalvf','tendlifmassbf','tendligroundf']\n",
    "scalar_variables = scalar_variables_ismip6\n",
    "experiments = experiments_ismip6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "def files_and_subdirectories(path):\n",
    "    files = []\n",
    "    directories = []\n",
    "    for f in os.listdir(path):\n",
    "        if os.path.isfile(os.path.join(path, f)):\n",
    "             files.append(f)\n",
    "        elif os.path.isdir(os.path.join(path, f)):\n",
    "            directories.append(f)\n",
    "    return directories, files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "#source_path = '/mnt/d/1_protect/0_sanity_check/IMAU/IMAUICE1'\n",
    "#source_path = '/mnt/d/1_protect/0_sanity_check/IMAU/IMAUICEtest'\n",
    "#source_path = '/mnt/d/1_protect/0_sanity_check/AWI/PISM1'\n",
    "#source_path = '/mnt/d/1_protect/0_sanity_check/DOE/MALI'\n",
    "#source_path = '/mnt/d/1_protect/0_sanity_check/ILTS_PIK/SICOPOLIS'\n",
    "source_path = '/mnt/d/1_protect/0_sanity_check/LSCE/GRISLI1'\n",
    "#source_path = '/mnt/d/1_protect/0_sanity_check/VUW/PISM'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 37/37 [00:00<00:00, 69.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ctrl_proj : compliance check processed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:23<00:00,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp09 : compliance check processed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(source_path,'compliance_checker_log.txt'),\"w\") as f:\n",
    "    experiment_directories,files = files_and_subdirectories(source_path)\n",
    "    today = datetime.date.today()\n",
    "\n",
    "    f.write('************************************************************************************\\n')\n",
    "    f.write('*************     Ice Sheet Model Simulations - Compliance Checker     *************\\n')\n",
    "    f.write('************************************************************************************\\n')\n",
    "    f.write('version: 0 \\n')\n",
    "    f.write('verification criteria: ismip6_criteria_v0.csv \\n')\n",
    "    f.write('date: '+ today.strftime(\"%Y/%m/%d\") +'\\n')\n",
    "    f.write('source: https://github.com/jbbarre/ISM_SimulationChecker \\n')\n",
    "    f.write(' \\n')\n",
    "    f.write('------------------------------------------------------------------------------------\\n')\n",
    "    f.write('Verified directory: '+ source_path +' \\n')\n",
    "    f.write('------------------------------------------------------------------------------------\\n')\n",
    "    f.write(' \\n')\n",
    "    f.write(' \\n')\n",
    "    f.write(' \\n')\n",
    "    f.write(' \\n')\n",
    "    f.write('====================================================================================\\n')\n",
    "    f.write('================                DETAILED RESULTS                    ================\\n')\n",
    "    f.write('====================================================================================\\n')\n",
    "    f.write('Tips: Use Cltr+F to look for specific problems. \\n')\n",
    "    f.write(' \\n')\n",
    "    \n",
    "    # total number of errors for the entire compliance check. \n",
    "    total_errors = 0\n",
    "    # total number of warnings for the entire compliance check. \n",
    "    total_warnings = 0\n",
    "    # total number of errors related to naming tests for the entire compliance check.\n",
    "    total_naming_errors = 0\n",
    "    # total number of errors related to numerical tests for the entire compliance check.\n",
    "    total_num_errors = 0\n",
    "    # total number of errors related to spatial tests for the entire compliance check.\n",
    "    total_spatial_errors = 0\n",
    "    # total number of errors related to time tests for the entire compliance check.\n",
    "    total_time_errors = 0\n",
    "\n",
    "    # gather all the naming issues to report in the synthesis.\n",
    "    report_naming_issues =[]\n",
    "\n",
    "    #initialize  files checked counter\n",
    "    file_counter = 0\n",
    "    #initialize  files checked counter\n",
    "    exp_counter = 0\n",
    "\n",
    "    for xp in experiment_directories:\n",
    "\n",
    "        exp_counter += 1\n",
    "\n",
    "        exp_dir,exp_files = files_and_subdirectories(os.path.join(source_path, xp))\n",
    "        exp_files=list(filter(lambda file: file.split('.')[-1] == 'nc', exp_files))\n",
    "        \n",
    "        # total number of errors for the experiment.\n",
    "        exp_errors = 0\n",
    "        # total number of errors related to naming tests of the experiment.\n",
    "        exp_naming_errors = 0\n",
    "        # total number of errors related to numerical tests of the experiment.\n",
    "        exp_num_errors = 0\n",
    "        # total number of errors related to spatial tests of the experiment.\n",
    "        exp_spatial_errors = 0\n",
    "        # total number of errors related to time tests of the experiment.\n",
    "        exp_time_errors = 0\n",
    "        # total number of warnings for the experiment.\n",
    "        exp_warnings = 0\n",
    "        # total number of warnings related to naming tests of the experiment.\n",
    "        exp_naming_warnings = 0\n",
    "        # total number of warnings related to numerical tests of the experiment.\n",
    "        exp_num_warnings = 0\n",
    "        # total number of warnings related to spatial tests of the experiment.\n",
    "        exp_spatial_warnings = 0\n",
    "        # total number of warnings related to time tests of the experiment.\n",
    "        exp_time_warnings = 0\n",
    "\n",
    "        # create the list of missing mandatory variables.List could be empty.\n",
    "        for i in exp_files:\n",
    "            file_name_split = i.split('_')\n",
    "            variable = file_name_split[0]\n",
    "            temp_mandatory_var = mandatory_variables\n",
    "            if  variable in mandatory_variables:\n",
    "                temp_mandatory_var.remove(variable)\n",
    "        \n",
    "        experiment_name = xp[:-3]\n",
    "        grid_resolution = int(xp[-2:])\n",
    "        \n",
    "        if experiment_name  in [dic['experiment'] for dic in experiments]:\n",
    "            f.write('\\n ')\n",
    "            f.write('-----------------------------------------\\n ')\n",
    "            f.write('Experiment: ' + experiment_name + ' \\n ')\n",
    "            f.write('-----------------------------------------\\n ')\n",
    "            f.write('\\n ')\n",
    "            if not temp_mandatory_var:\n",
    "                f.write('Mandatory variables Test: ' + xp + ' : all mandatory variables exist. \\n')\n",
    "            else:\n",
    "                f.write('ERROR: In experiment ' +  xp +', these mandatory variable(s) is (are) missing: '+ str(temp_mandatory_var)+'\\n')\n",
    "                exp_errors += 1\n",
    "\n",
    "            for file in tqdm(exp_files):\n",
    "\n",
    "                file_counter += 1\n",
    "\n",
    "                # total number of errors for the variable.\n",
    "                var_errors = 0\n",
    "                # total number of warnings for the variable.\n",
    "                var_warnings = 0\n",
    "                # total number of errors related to the naming tests of the variable.\n",
    "                var_naming_errors = 0\n",
    "                # total number of errors related to the numerical tests of the variable.\n",
    "                var_num_errors = 0\n",
    "                # total number of errors related to the spatial tests of the variable.\n",
    "                var_spatial_errors = 0\n",
    "                # total number of errors related to the time tests of the variable.\n",
    "                var_time_errors = 0\n",
    "\n",
    "\n",
    "                # total number of warnings for the variable.\n",
    "                var_warnings = 0\n",
    "                # total number of warnings for the variable.\n",
    "                var_warnings = 0\n",
    "                # total number of warnings related to the naming tests of the variable.\n",
    "                var_naming_warnings = 0\n",
    "                # total number of warnings related to the numerical tests of the variable.\n",
    "                var_num_warnings = 0\n",
    "                # total number of warnings related to the spatial tests of the variable.\n",
    "                var_spatial_warnings = 0\n",
    "                # total number of warnings related to the time tests of the variable.\n",
    "                var_time_warnings = 0\n",
    "\n",
    "                split_path=os.path.normpath(file).split(os.sep)\n",
    "                file_name = split_path[-1]\n",
    "                file_name_split = file_name.split('_')\n",
    "                \n",
    "                considered_variable = file_name_split[0]\n",
    "                region = file_name_split[1]\n",
    "                group  = file_name_split[2]\n",
    "                model = file_name_split[3]\n",
    "                file_extention = file_name_split[len(file_name_split)-1][-2:]\n",
    "                \n",
    "                # Load the netcdf file\n",
    "                ds = xr.open_dataset(os.path.join(source_path,xp,file))\n",
    "\n",
    "                # Load local variables included in the netcdf file\n",
    "                file_variables = list(ds.data_vars)\n",
    "\n",
    "                # test file extention\n",
    "\n",
    "                if file_extention != 'nc':\n",
    "                    f.write(' !! '+file_name+' is not a NETCDF file. The compliance check is ignored.'+'\\n')\n",
    "                    #f.write (' \\n')\n",
    "                    \n",
    "                else: \n",
    "                    # test if the structure of the file name is correct\n",
    "                    if int(len(file_name_split)) == 5:\n",
    "                        # NAMING TEST\n",
    "                        # test if experiment name (host directory) and exp in variable file name are the same.\n",
    "                                        # name of the experiment in the file name.\n",
    "                        experiment_varname = file_name_split[4][:-3]\n",
    "                        if experiment_varname == experiment_name:\n",
    "                            # test if the file is not a scalar variable then run check else check next variable\n",
    "                            if considered_variable in variables:\n",
    "                                f.write (' \\n')\n",
    "                                f.write('Experiment: '+ experiment_name + ' - File: ' + file_name + '\\n')\n",
    "                                f.write(' \\n')\n",
    "                                # TEST data dimensions: x,y,t ok?\n",
    "                                header_ds = ds.to_dict(data=False)\n",
    "                                if len(header_ds['coords']) == 3:\n",
    "                                    # NAMING TEST\n",
    "                                    if region.upper() in ['AIS', 'GIS']:\n",
    "                                        #f.write('Studied Region: ' + region + '\\n')\n",
    "                                        if region == 'AIS':\n",
    "                                            # grid_exten[Xbottomleft,Ybottomleft,Xtopright,Ytopright]\n",
    "                                            grid_extent = [-3040000,-3040000,3040000,3040000]\n",
    "                                            possible_resolution = [1,2,4,8,16,32] \n",
    "                                        else: \n",
    "                                            # GIS Grid\n",
    "                                            grid_extent = [-720000,-3450000,960000,-570000]\n",
    "                                            possible_resolution = [1,2,4,5,10,20]\n",
    "\n",
    "\n",
    "                                        for ivar in file_variables:\n",
    "                                            if ivar in ismip_var:\n",
    "                                                f.write('** Tested Variable: '+ivar+'\\n')\n",
    "                                                f.write (' \\n')\n",
    "                                                # get index in the ismip_var list\n",
    "                                                var_index = [k for k in range(len(ismip_var)) if ismip_var[k]==ivar]\n",
    "                                                \n",
    "                                            # NUMERICAL TESTS\n",
    "                                                f.write('NUMERICAL Tests \\n')\n",
    "                                                # check the unit\n",
    "                                                if ds[ivar].attrs['units'] == ismip_meta[var_index[0]]['units']:\n",
    "                                                    f.write(' - The unit is correct: ' + ds[ivar].attrs['units']+'\\n')\n",
    "                                                else:\n",
    "                                                    f.write(' - ERROR: The unit of the variable is ' + ds[ivar].attrs['units'] + ' and should be ' + ismip_meta[var_index[0]]['units']+' \\n')\n",
    "                                                    var_num_errors += 1 \n",
    "                                                # check the min value\n",
    "                                                if ds[ivar].min().item()>=ismip_meta[var_index[0]]['min_value_'+region.lower()]:\n",
    "                                                    f.write(' - The minimum value successfully verified.\\n')\n",
    "                                                else:\n",
    "                                                    f.write(' - ERROR: The minimum value(' + str(ds[ivar].min().values.item(0)) + ') is out of range. Min value accepted:' + str(ismip_meta[var_index[0]]['min_value_'+region.lower()])+'\\n')\n",
    "                                                    var_num_errors += 1 \n",
    "                                                # check the max value\n",
    "                                                if ds[ivar].max().item()<=ismip_meta[var_index[0]]['max_value_'+region.lower()]:\n",
    "                                                        f.write(' - The maximum value successfully verified.\\n')\n",
    "                                                else:\n",
    "                                                    f.write(' - ERROR: The maximum value(' + str(ds[ivar].max().values.item(0)) + ') is out of range. Max value accepted:' + str(ismip_meta[var_index[0]]['max_value_'+region.lower()])+'\\n')\n",
    "                                                    var_num_errors += 1\n",
    "                                                                            \n",
    "\n",
    "                                            # SPATIAL TESTS\n",
    "                                                # SPATIAL:Check spatial extent of the grid\n",
    "                                                f.write('SPATIAL Tests \\n')\n",
    "                                                # get the grid from the file\n",
    "                                                coords = ds.coords.to_dataset()\n",
    "                                                Xbottomleft=int(min(coords['x']).values.item())\n",
    "                                                Ybottomleft=int(min(coords['y']).values.item())\n",
    "                                                Xtopright=int(max(coords['x']).values.item())\n",
    "                                                Ytopright=int(max(coords['y']).values.item())\n",
    "\n",
    "                                                if Xbottomleft == grid_extent[0] & Ybottomleft == grid_extent[1]:\n",
    "                                                    f.write(' - Grid: Lowest left corner is well defined.\\n')\n",
    "                                                else:    \n",
    "                                                    f.write(' - ERROR: Lowest left corner of the grid [' + str(Xbottomleft) + ',' + str(Ybottomleft) + '] is not correctly defined. [' + str(grid_extent[0])+ ',' + str(grid_extent[1]) + '] Expected\\n')\n",
    "                                                    var_spatial_errors += 1\n",
    "                                                if Xtopright == grid_extent[2] & Ytopright == grid_extent[3]:\n",
    "                                                    f.write(' - Grid: Upper right corner is well defined.\\n')\n",
    "                                                else:    \n",
    "                                                    f.write(' - ERROR: Upper rigth corner of the grid [' + str(Xtopright) + ',' + str(Ytopright) + '] is not correctly defined. [' + str(grid_extent[0]) + ',' + str(grid_extent[1])+ '] Expected\\n')\n",
    "                                                    var_spatial_errors += 1\n",
    "\n",
    "                                                #SPATIAL:check the spatial resolution\n",
    "                                                Xresolution = round((coords['x'][1].values-coords['x'][0].values)/1000,0)\n",
    "                                                Yresolution = round((coords['y'][1].values-coords['y'][0].values)/1000,0)\n",
    "                                                if Xresolution in set(possible_resolution) and Yresolution in set(possible_resolution):\n",
    "                                                    if Xresolution == grid_resolution and Yresolution == grid_resolution:\n",
    "                                                        f.write(' - The grid resolution (' + str(Xresolution) + ') was successfully verified.\\n')\n",
    "                                                    else:\n",
    "                                                        f.write(' - ERROR: The grid resolution ( ' + str(Xresolution) + ' or ' + str(Yresolution) + ') is different of ' + str(grid_resolution) + 'declared in the file name.\\n')\n",
    "                                                        var_spatial_errors += 1\n",
    "                                                else:\n",
    "                                                    f.write(' - Error: x: ' + str(Xresolution) + ',y: ' + str(Yresolution) + ' is not an authorized grid resolution.\\n')\n",
    "                                                    var_spatial_errors += 1\n",
    "\n",
    "                                            # TIME TESTS\n",
    "                                                f.write('TIME Tests \\n')\n",
    "                                                start_exp = pd.to_datetime(min(ds['time']).values.astype(\"datetime64[ns]\"))\n",
    "                                                end_exp  = pd.to_datetime(max(ds['time']).values.astype(\"datetime64[ns]\"))\n",
    "                                                avgyear = 365.2425        # pedants definition of a year length with leap years\n",
    "                                                duration_days = (end_exp - start_exp)\n",
    "                                                duration_years = round(pd.to_numeric(duration_days.days / avgyear))\n",
    "\n",
    "                                                index_exp=[dic['experiment'] for dic in experiments].index(experiment_name)\n",
    "                                                #test if start_exp and end_exp are datetime format\n",
    "                                                if isinstance(start_exp, datetime.datetime) & isinstance(end_exp, datetime.datetime):\n",
    "                                                    # test Starting date\n",
    "                                                    if experiments[index_exp]['startinf'] <= start_exp <= experiments[index_exp]['startsup']:\n",
    "                                                        f.write(' - Experiment starts correctly on ' + start_exp.strftime('%Y-%m-%d') + '.\\n')\n",
    "                                                    else:\n",
    "                                                        f.write(' - ERROR: the experiment starts the ' + start_exp.strftime('%Y-%m-%d') + '. The date should be comprised between ' + experiments[index_exp]['startinf'].strftime('%Y-%m-%d') + ' and ' + experiments[index_exp]['startsup'].strftime('%Y-%m-%d')+'\\n')\n",
    "                                                        var_time_errors += 1\n",
    "                                                    # test Ending date\n",
    "                                                    if experiments[index_exp]['endinf'] <= end_exp <= experiments[index_exp]['endsup']:\n",
    "                                                        f.write(' - Experiment ends correctly on ' + end_exp.strftime('%Y-%m-%d') + '.\\n')\n",
    "                                                    else:\n",
    "                                                        f.write(' - ERROR: the experiment ends on ' + end_exp.strftime('%Y-%m-%d') + '. The date should be comprised between ' + experiments[index_exp]['endinf'].strftime('%Y-%m-%d') + ' and ' + experiments[index_exp]['endsup'].strftime('%Y-%m-%d')+'\\n')\n",
    "                                                        var_time_errors += 1\n",
    "                                                    # test Duration\n",
    "                                                    if experiments[index_exp]['duration']-1 <= duration_years <= experiments[index_exp]['duration']:\n",
    "                                                        f.write(\" - Experiment lasts \" + str(duration_years) + ' years.\\n')\n",
    "                                                    else:\n",
    "                                                        f.write(' - ERROR: the experiment lasts ' + str(duration_years) + ' years. The duration should be ' + str(experiments[index_exp]['duration']) + ' years\\n')\n",
    "                                                        var_time_errors += 1\n",
    "                                                    # test Time step\n",
    "                                                    if isinstance((ds['time'].values[11]-ds['time'].values[10]),datetime.timedelta):\n",
    "                                                        time_step = (ds['time'].values[11]-ds['time'].values[10]).days\n",
    "                                                    else:   \n",
    "                                                        if isinstance((ds['time'].values[11]-ds['time'].values[10]),np.timedelta64):\n",
    "                                                            time_step = np.timedelta64(ds['time'].values[11]-ds['time'].values[10], 'D')/ np.timedelta64(1, 'D')\n",
    "                                                        else:    \n",
    "                                                            time_step = ds['time'].values[11]-ds['time'].values[10]\n",
    "\n",
    "                                                    if 360<=time_step<=367:\n",
    "                                                        f.write(' - Time step: ' + str(time_step) + ' days' + '\\n')\n",
    "                                                    else:\n",
    "                                                        f.write(' - ERROR: the time step(' + str(time_step) + ') should be comprised between [360,367].\\n')\n",
    "                                                        var_time_errors += 1\n",
    "                                                else: \n",
    "                                                    #not a datetime format\n",
    "                                                    f.write(' - ERROR: the time format is not compatible with datetime module. It should be like yyyy-mm-dd.\\n')\n",
    "                                                    var_time_errors += 1\n",
    "                                    else:\n",
    "                                        # NAMING TEST\n",
    "                                        f.write('- ERROR: Region ' + region + 'not recognized. It should be AIS or GIS. The compliance check has been interrupted for this variable.\\n')\n",
    "                                        report_naming_issues.append('Compliance check ignored: region (AIS/GIS) not identified in the file ' + file_name + ' due to wrong naming.')\n",
    "                                        var_naming_errors += 1\n",
    "                                else:\n",
    "                                    ## TEST data dimensions: x,y,t not ok\n",
    "                                    f.write('- ERROR: Compliance check ignored: one (or several) of the mandatory dimensions (x,y,t) is missing.\\n')\n",
    "                                    f.write('                                   Only ' + str(list(header_ds['coords'].keys())) + ' has been detected.\\n')\n",
    "                                    report_naming_issues.append('Compliance check ignored: one (or several) of the mandatory dimensions (x,y,t) is missing in ' + file_name )\n",
    "                                    var_naming_errors += 1\n",
    "\n",
    "                                var_errors = var_errors + var_naming_errors + var_num_errors + var_spatial_errors + var_time_errors\n",
    "                                var_warnings = var_warnings + var_num_warnings + var_spatial_warnings + var_time_warnings\n",
    "                                \n",
    "                                f.write('\\n')        \n",
    "                                f.write('******************************************************'+'\\n')\n",
    "                                f.write(experiment_name + ' - ' + file_name+'\\n')\n",
    "                                if var_errors > 0:\n",
    "                                    f.write(str(var_errors) + ' error(s). Please review before sharing.'+'\\n')\n",
    "                                else:\n",
    "                                    f.write('No errors. Good job !'+'\\n')\n",
    "                                if var_warnings > 0:\n",
    "                                    f.write(str(var_warnings) + ' warning(s). Please review before sharing.'+'\\n')\n",
    "                                else:\n",
    "                                    f.write('No warnings.'+'\\n')\n",
    "                                f.write('******************************************************'+'\\n')\n",
    "                        else:\n",
    "                            # NAMING TEST\n",
    "                            f.write(' - ERROR: in the file name ' + file_name + ', the experiment name ('+experiment_varname+') do not match the directory name: ' + experiment_name + '.\\n')\n",
    "                            report_naming_issues.append('Compliance check ignored: in the file name ' + file_name + ', the experiment name (' + experiment_varname + ') do not match the directory name: ' + experiment_name + '.\\n')\n",
    "                            var_naming_errors += 1\n",
    "\n",
    "                            var_errors = var_errors + var_naming_errors + var_num_errors + var_spatial_errors + var_time_errors\n",
    "                            var_warnings = var_warnings + var_num_warnings + var_spatial_warnings + var_time_warnings\n",
    "\n",
    "                    else: \n",
    "                        # NAMING TEST\n",
    "                        f.write(' - ERROR: the file name ' + file_name + ' do not follow the naming convention.\\n')\n",
    "                        report_naming_issues.append('Compliance check ignored: file ' + file_name + ' do not follow the naming convention.')\n",
    "                        var_naming_errors += 1\n",
    "\n",
    "                        var_errors = var_errors + var_naming_errors + var_num_errors + var_spatial_errors + var_time_errors\n",
    "                        var_warnings = var_warnings + var_num_warnings + var_spatial_warnings + var_time_warnings\n",
    "\n",
    "                exp_naming_errors = exp_naming_errors + var_naming_errors\n",
    "                exp_num_errors = exp_num_errors + var_num_errors\n",
    "                exp_spatial_errors = exp_spatial_errors + var_spatial_errors\n",
    "                exp_time_errors = exp_time_errors + var_time_errors               \n",
    "                exp_num_warnings = exp_num_warnings + var_num_warnings\n",
    "                exp_spatial_warnings = exp_spatial_warnings + var_spatial_warnings\n",
    "                exp_time_warnings = exp_time_warnings + var_time_warnings\n",
    "                \n",
    "\n",
    "        else:\n",
    "            f.write('\\n ')\n",
    "            f.write('-----------------------------------------\\n ')\n",
    "            f.write('Experiment: ' + experiment_name + ' \\n ')\n",
    "            f.write('-----------------------------------------\\n ')\n",
    "            f.write('\\n ')\n",
    "            f.write('ERROR: The compliance check is ignored for experiment ' + experiment_name + ' as it is not in [hist, ctrl, ctrl_proj, exp01, exp02, exp03, exp04, exp05, exp06, exp07, exp08, exp09, exp10, exp11, exp12, exp13]. \\n')\n",
    "            exp_naming_errors +=1\n",
    "            report_naming_issues.append('Compliance check ignored : experiment ' + experiment_name + ' not in the experiments list.')\n",
    "       \n",
    "        #feedback terminal\n",
    "        print(experiment_name,': compliance check processed.')\n",
    "            # Update counters.\n",
    "        total_naming_errors += exp_naming_errors\n",
    "        total_num_errors += exp_num_errors\n",
    "        total_spatial_errors += exp_spatial_errors\n",
    "        total_time_errors += exp_time_errors\n",
    "\n",
    "\n",
    "    total_errors = total_naming_errors + total_num_errors + total_spatial_errors + total_time_errors\n",
    "\n",
    "\n",
    "###################################################        \n",
    "# insert synthesis at the top of the log file\n",
    "###################################################\n",
    "\n",
    "with open(os.path.join(source_path,'compliance_checker_log.txt'), \"r\") as f:\n",
    "    contents = f.readlines()\n",
    "# lines insert position\n",
    "iline =  11\n",
    "contents.insert(iline, str(exp_counter) + ' experiments checked.\\n')\n",
    "iline += 1\n",
    "contents.insert(iline, str(file_counter) + ' files checked (Scalar files are ignored).\\n')\n",
    "iline += 2\n",
    "contents.insert(iline, str(total_errors) + ' error(s) detected.\\n')\n",
    "iline += 1\n",
    "contents.insert(iline, '  - Naming Tests   : ' + str(total_naming_errors) + ' error(s)\\n')\n",
    "iline += 1\n",
    "contents.insert(iline, '  - Numerical Tests: ' + str(total_num_errors) + ' error(s)\\n')\n",
    "iline += 1\n",
    "contents.insert(iline, '  - Spatial Tests  : ' + str(total_spatial_errors) + ' error(s)\\n')\n",
    "iline += 1\n",
    "contents.insert(iline, '  - Time Tests     : ' + str(total_time_errors) + ' error(s)\\n')\n",
    "iline += 2\n",
    "contents.insert(iline, str(total_warnings) + ' warning(s) detected.\\n')\n",
    "iline += 2\n",
    "contents.insert(iline, 'Naming tests errors report: \\n' )\n",
    "iline += 1\n",
    "for i in range(iline,len(report_naming_issues)):\n",
    "    contents.insert(i, '  - ' + report_naming_issues[i-24] + '\\n')\n",
    "contents.insert(iline+len(report_naming_issues), '\\n')\n",
    "\n",
    "with open(os.path.join(source_path,'compliance_checker_log.txt'), \"w\") as f:\n",
    "    f.writelines(contents)\n",
    "\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_exp = pd.to_datetime(min(ds['time']).values.astype(\"datetime64[ns]\"))\n",
    "end_exp  = pd.to_datetime(max(ds['time']).values.astype(\"datetime64[ns]\"))\n",
    "avgyear = 365.2425        # pedants definition of a year length with leap years\n",
    "duration_days = (end_exp - start_exp)\n",
    "duration_years = round(pd.to_numeric(duration_days.days / avgyear))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance((ds['time'].values[11]-ds['time'].values[10]),datetime.timedelta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance((ds['time'].values[11]-ds['time'].values[10]),np.timedelta64)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "365.0"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.timedelta64(ds['time'].values[11]-ds['time'].values[10], 'D')/ np.timedelta64(1, 'D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('Pyspatial')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0a4327e86c77f61d5ffc06346466511d63eb76b6c0151c8bd0a68f2c3e31d44c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
